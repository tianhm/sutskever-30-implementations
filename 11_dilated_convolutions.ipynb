{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper 11: Multi-Scale Context Aggregation by Dilated Convolutions\n",
    "## Fisher Yu, Vladlen Koltun (2015)\n",
    "\n",
    "### Dilated/Atrous Convolutions for Large Receptive Fields\n",
    "\n",
    "Expand receptive field without losing resolution or adding parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard vs Dilated Convolution\n",
    "\n",
    "**Standard**: Continuous kernel  \n",
    "**Dilated**: Kernel with gaps (dilation rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilated_conv1d(input_seq, kernel, dilation=1):\n",
    "    \"\"\"\n",
    "    1D dilated convolution\n",
    "    \n",
    "    dilation=1: standard convolution\n",
    "    dilation=2: skip every other position\n",
    "    dilation=4: skip 3 positions\n",
    "    \"\"\"\n",
    "    input_len = len(input_seq)\n",
    "    kernel_len = len(kernel)\n",
    "    \n",
    "    # Effective kernel size with dilation\n",
    "    effective_kernel_len = (kernel_len - 1) * dilation + 1\n",
    "    output_len = input_len - effective_kernel_len + 1\n",
    "    \n",
    "    output = []\n",
    "    for i in range(output_len):\n",
    "        # Apply dilated kernel\n",
    "        result = 0\n",
    "        for k in range(kernel_len):\n",
    "            pos = i + k * dilation\n",
    "            result += input_seq[pos] * kernel[k]\n",
    "        output.append(result)\n",
    "    \n",
    "    return np.array(output)\n",
    "\n",
    "# Test\n",
    "signal = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "kernel = np.array([1, 1, 1])\n",
    "\n",
    "out_d1 = dilated_conv1d(signal, kernel, dilation=1)\n",
    "out_d2 = dilated_conv1d(signal, kernel, dilation=2)\n",
    "out_d4 = dilated_conv1d(signal, kernel, dilation=4)\n",
    "\n",
    "print(f\"Input: {signal}\")\n",
    "print(f\"Kernel: {kernel}\")\n",
    "print(f\"\\nDilation=1 (standard): {out_d1}\")\n",
    "print(f\"Dilation=2: {out_d2}\")\n",
    "print(f\"Dilation=4: {out_d4}\")\n",
    "print(f\"\\nReceptive field grows exponentially with dilation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Receptive Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how dilation affects receptive field\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 8))\n",
    "\n",
    "for ax, dilation, title in zip(axes, [1, 2, 4], \n",
    "                                ['Dilation=1 (Standard)', 'Dilation=2', 'Dilation=4']):\n",
    "    # Show which positions are used\n",
    "    positions = [0, dilation, 2*dilation]\n",
    "    \n",
    "    ax.scatter(range(10), signal, s=200, c='lightblue', edgecolors='black', zorder=2)\n",
    "    ax.scatter(positions, signal[positions], s=300, c='red', edgecolors='black', \n",
    "              marker='*', zorder=3, label='Used by kernel')\n",
    "    \n",
    "    # Draw connections\n",
    "    for pos in positions:\n",
    "        ax.plot([pos, pos], [0, signal[pos]], 'r--', alpha=0.5, linewidth=2)\n",
    "    \n",
    "    ax.set_title(f'{title} - Receptive Field: {1 + 2*dilation} positions')\n",
    "    ax.set_xlabel('Position')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(-0.5, 9.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Dilated Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilated_conv2d(input_img, kernel, dilation=1):\n",
    "    \"\"\"\n",
    "    2D dilated convolution\n",
    "    \"\"\"\n",
    "    H, W = input_img.shape\n",
    "    kH, kW = kernel.shape\n",
    "    \n",
    "    # Effective kernel size\n",
    "    eff_kH = (kH - 1) * dilation + 1\n",
    "    eff_kW = (kW - 1) * dilation + 1\n",
    "    \n",
    "    out_H = H - eff_kH + 1\n",
    "    out_W = W - eff_kW + 1\n",
    "    \n",
    "    output = np.zeros((out_H, out_W))\n",
    "    \n",
    "    for i in range(out_H):\n",
    "        for j in range(out_W):\n",
    "            result = 0\n",
    "            for ki in range(kH):\n",
    "                for kj in range(kW):\n",
    "                    img_i = i + ki * dilation\n",
    "                    img_j = j + kj * dilation\n",
    "                    result += input_img[img_i, img_j] * kernel[ki, kj]\n",
    "            output[i, j] = result\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Create test image with pattern\n",
    "img = np.zeros((16, 16))\n",
    "img[7:9, :] = 1  # Horizontal line\n",
    "img[:, 7:9] = 1  # Vertical line (cross)\n",
    "\n",
    "# 3x3 edge detection kernel\n",
    "kernel = np.array([[-1, -1, -1],\n",
    "                   [-1,  8, -1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "# Apply with different dilations\n",
    "result_d1 = dilated_conv2d(img, kernel, dilation=1)\n",
    "result_d2 = dilated_conv2d(img, kernel, dilation=2)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(img, cmap='gray')\n",
    "axes[0].set_title('Input Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(result_d1, cmap='RdBu')\n",
    "axes[1].set_title('Dilation=1 (3x3 receptive field)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(result_d2, cmap='RdBu')\n",
    "axes[2].set_title('Dilation=2 (5x5 receptive field)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Larger dilation → larger receptive field → captures wider context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Scale Context Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleContext:\n",
    "    \"\"\"Stack dilated convolutions with increasing dilation rates\"\"\"\n",
    "    def __init__(self, kernel_size=3):\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        # Create kernels for each scale\n",
    "        self.kernels = [\n",
    "            np.random.randn(kernel_size, kernel_size) * 0.1\n",
    "            for _ in range(4)\n",
    "        ]\n",
    "        \n",
    "        # Dilation rates: 1, 2, 4, 8\n",
    "        self.dilations = [1, 2, 4, 8]\n",
    "    \n",
    "    def forward(self, input_img):\n",
    "        \"\"\"\n",
    "        Apply multi-scale dilated convolutions\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        \n",
    "        current = input_img\n",
    "        for kernel, dilation in zip(self.kernels, self.dilations):\n",
    "            # Apply dilated conv\n",
    "            out = dilated_conv2d(current, kernel, dilation)\n",
    "            outputs.append(out)\n",
    "            \n",
    "            # Pad back to original size (simplified)\n",
    "            pad_h = (input_img.shape[0] - out.shape[0]) // 2\n",
    "            pad_w = (input_img.shape[1] - out.shape[1]) // 2\n",
    "            current = np.pad(out, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant')\n",
    "            \n",
    "            # Crop to match input size\n",
    "            current = current[:input_img.shape[0], :input_img.shape[1]]\n",
    "        \n",
    "        return outputs, current\n",
    "\n",
    "# Test multi-scale\n",
    "msc = MultiScaleContext(kernel_size=3)\n",
    "scales, final = msc.forward(img)\n",
    "\n",
    "print(f\"Receptive fields at each layer:\")\n",
    "for i, d in enumerate(msc.dilations):\n",
    "    rf = 1 + 2 * d * (len(msc.dilations) - 1)\n",
    "    print(f\"  Layer {i+1} (dilation={d}): {rf}x{rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Dilated Convolution:\n",
    "- Insert zeros (holes) between kernel weights\n",
    "- **Receptive field**: $(k-1) \\cdot d + 1$ where $k$=kernel size, $d$=dilation\n",
    "- **Same parameters** as standard convolution\n",
    "- **Larger context** without pooling\n",
    "\n",
    "### Advantages:\n",
    "- ✅ Exponential receptive field growth\n",
    "- ✅ No resolution loss (vs pooling)\n",
    "- ✅ Same parameter count\n",
    "- ✅ Multi-scale context aggregation\n",
    "\n",
    "### Applications:\n",
    "- **Semantic segmentation**: Dense prediction tasks\n",
    "- **Audio generation**: WaveNet\n",
    "- **Time series**: TCN (Temporal Convolutional Networks)\n",
    "- **Any task needing large receptive fields**\n",
    "\n",
    "### Comparison:\n",
    "| Method | Receptive Field | Resolution | Parameters |\n",
    "|--------|----------------|------------|------------|\n",
    "| Standard Conv | Small | Full | Low |\n",
    "| Pooling | Large | Reduced | Low |\n",
    "| Large Kernel | Large | Full | High |\n",
    "| **Dilated Conv** | **Large** | **Full** | **Low** |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
